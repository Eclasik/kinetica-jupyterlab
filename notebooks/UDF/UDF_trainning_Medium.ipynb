{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gpudb\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define input type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_ip=\"p4.rewreu.org\"\n",
    "\n",
    "input_type = \"\"\"\n",
    "    {\n",
    "       \"type\": \"record\",\n",
    "       \"name\": \"input_type\",\n",
    "       \"fields\": [{\"name\":\"y\",\"type\":\"float\"},\n",
    "       ]\n",
    "    }  \"\"\".replace(' ', '').replace('\\n', '')\n",
    "for i in range(10):\n",
    "    l=\"\"\"{\"name\":\"x\"\"\"+str(i)+\"\"\"\",\"type\":\"float\"},\"\"\" if i<10-1 else \"\"\"{\"name\":\"x\"\"\"+str(i)+\"\"\"\",\"type\":\"float\"}\"\"\"\n",
    "    input_type=input_type[:-2]+l+input_type[-2:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_db = gpudb.GPUdb(encoding='BINARY', host=host_ip, port=\"9191\")\n",
    "response = h_db.create_type(type_definition=input_type, label=\"X\", properties={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if h_db.has_table(table_name=\"X\")['table_exists']:\n",
    "    h_db.clear_table(table_name=\"X\")\n",
    "response = h_db.create_table(table_name=\"X\", type_id=response['type_id'],\n",
    "                             options={\"collection_name\": \"LinearReg\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 % loaded\n",
      "40.0 % loaded\n",
      "60.0 % loaded\n",
      "80.0 % loaded\n",
      "100.0 % loaded\n",
      "X table has 10000 number of record inserted\n"
     ]
    }
   ],
   "source": [
    "data_pack_size=10\n",
    "Input_table=\"X\"\n",
    "x=np.random.random([1000,10])\n",
    "Y=x.sum(axis=1)+np.random.random([1000])*3\n",
    "i = 0\n",
    "encoded_obj_list = []\n",
    "# for data in \n",
    "for data, label in zip(x, Y):\n",
    "    datum = collections.OrderedDict()\n",
    "    datum[\"y\"]=label\n",
    "    for k in range(10):\n",
    "        datum[\"x\"+str(k)]=data[k]\n",
    "    encoded_obj_list.append(h_db.encode_datum(input_type, datum))\n",
    "    i = i + 1\n",
    "    if i % data_pack_size == 0:\n",
    "        response = h_db.insert_records(table_name=Input_table, data=encoded_obj_list, list_encoding='binary',\n",
    "                                       options={})  # the list_encoding and options can be omitted\n",
    "        encoded_obj_list = []\n",
    "        pct=float(i)/float(x.shape[0])*100.0\n",
    "        if pct==int(pct) and pct%20 ==0:\n",
    "            print(str(pct)+\" % loaded\")\n",
    "if encoded_obj_list != []:\n",
    "    response = h_db.insert_records(table_name=Input_table, data=encoded_obj_list, list_encoding='binary', options={})\n",
    "\n",
    "response = h_db.insert_records(table_name=Input_table, data=encoded_obj_list,\n",
    "                               list_encoding='binary', options={})  # the list_encoding and options can be omitted\n",
    "print(\"%s table has %d number of record inserted\"%(Input_table,i*data_pack_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainingReg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainingReg.py\n",
    "import gpudb\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "from kineticaIO import kineticaIO\n",
    "import pickle\n",
    "from kinetica_proc import ProcData\n",
    "\n",
    "# modify according to environment\n",
    "HOSTIP = '127.0.0.1'  # trainning on the head node, no need to change\n",
    "in_table_name = \"X\"\n",
    "train_data_size = 10000  # random sampling data, for Kmeans clustering, there is no batch feed, so to avoid crashing, randomly \n",
    "\n",
    "\n",
    "# choose a smaller subset of data to train. \n",
    "\n",
    "def run():\n",
    "    proc_data = ProcData()\n",
    "    h_db = gpudb.GPUdb(encoding='BINARY', host=HOSTIP, port=9191)\n",
    "    mydf1 = pd.DataFrame()\n",
    "    response = h_db.show_table(table_name=in_table_name, options={\"get_sizes\": \"true\"})\n",
    "    size = response['sizes'][0]\n",
    "    batch_size = 100\n",
    "    for i in range(train_data_size // batch_size):\n",
    "        offset = random.randint(0, size)\n",
    "        response = h_db.get_records(table_name='X', offset=offset, limit=batch_size)\n",
    "        res_decoded = gpudb.GPUdbRecord.decode_binary_data(response[\"type_schema\"], response[\"records_binary\"])\n",
    "        mydf1 = mydf1.append(pd.DataFrame(res_decoded))\n",
    "    y = mydf1[\"y\"]\n",
    "    x = mydf1.drop(['y'], axis=1)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X=x, y=y)\n",
    "    # save model to database\n",
    "    s = pickle.dumps(lr)\n",
    "    kio = kineticaIO(h_db)\n",
    "    kio.Model2Kinetica(pbfile=s, ModelName=\"LinearReg_Model\", Loss=-99, COLLECTION=\"MASTER\")\n",
    "    proc_data.complete()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering proc...\n",
      "Executing proc...\n",
      "Proc was launched successfully with run_id: 6\n",
      "process is running... \n",
      "process is running... \n",
      "process is running... \n",
      "process is running... \n",
      "process is running... \n",
      "process is running... \n",
      "process is running... \n",
      "('total running time is ', datetime.timedelta(0, 7, 241556))\n",
      "Final Proc state: complete\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import time\n",
    "import gpudb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "host_ip = \"p4.rewreu.org\"  # dev machine\n",
    "PORT = '9191'\n",
    "proc_name = 'lr_train'\n",
    "filelist = ['trainingReg.py', 'kineticaIO.py']\n",
    "\n",
    "\n",
    "# Register UDF\n",
    "def Register_UDF(h_db, proc_name=proc_name, filelist=filelist):\n",
    "    files = {}\n",
    "    for ifile in filelist:\n",
    "        with open(ifile, 'rb') as f:\n",
    "            files[ifile.split(\"/\")[-1]] = f.read()\n",
    "    if h_db.has_proc(proc_name)['proc_exists']:\n",
    "        h_db.delete_proc(proc_name)\n",
    "    print(\"Registering proc...\")\n",
    "    response = h_db.create_proc(proc_name, 'nondistributed', files, 'python', [filelist[0]], {})\n",
    "\n",
    "\n",
    "# Execute UDF\n",
    "def execute_UDF(h_db, proc_name=proc_name):\n",
    "    print(\"Executing proc...\")\n",
    "    response = h_db.execute_proc(proc_name, {}, {}, [], {}, [], {})\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    h_db = gpudb.GPUdb(encoding='BINARY', host=host_ip, port=PORT)\n",
    "    Register_UDF(h_db)\n",
    "    response = execute_UDF(h_db)\n",
    "    start_time = datetime.now()\n",
    "    if response['status_info']['status'] == 'OK':\n",
    "        run_id = response['run_id']\n",
    "        print('Proc was launched successfully with run_id: ' + run_id)\n",
    "        while h_db.show_proc_status(run_id)['overall_statuses'][run_id] == 'running':\n",
    "            time.sleep(1)\n",
    "            print('process is running... ')\n",
    "        final_proc_state = h_db.show_proc_status(run_id)['overall_statuses'][run_id]\n",
    "        print(\"total running time is \", datetime.now() - start_time)\n",
    "        print('Final Proc state: ' + final_proc_state)\n",
    "        if final_proc_state == 'error':\n",
    "            raise RuntimeError('proc error')\n",
    "    else:\n",
    "        print('Error launching proc; response: ')\n",
    "        print(response)\n",
    "        raise RuntimeError('proc error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n",
      "Catalog [KINETICA]\n",
      "Time 0.181\n",
      "+----------------------------------------+------------------------------+\n",
      "| model_id                               |            Data_Time_created |\n",
      "+----------------------------------------+------------------------------+\n",
      "| 49c835e4-8609-11e8-bc7f-984be16d139a   |   2018-07-12 19:25:05.000000 |\n",
      "+----------------------------------------+------------------------------+\n",
      "Rows read = 1\n",
      "Exec time 0.055 Fetch time 0.025\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "./kisql/kisql -h p4.rewreu.org -sql \\\n",
    "\"\"\"\n",
    "SELECT\n",
    "    model_id, Data_Time_created\n",
    "FROM TFmodel\n",
    "where model = 'LinearReg_Model'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write inference code to local file\n",
    "<font color='red'>modify the model_id according to the table above</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting infer_Reg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile infer_Reg.py\n",
    "import gpudb\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "from kineticaIO import kineticaIO\n",
    "import pickle\n",
    "from kinetica_proc import ProcData\n",
    "\n",
    "Model_id=\"49c835e4-8609-11e8-bc7f-984be16d139a\"\n",
    "headnode='127.0.0.1' # trainning on the head node\n",
    "\n",
    "cols=[\"x\"+str(i) for i in range(10)]\n",
    "cols.append(\"y\")\n",
    "def run():\n",
    "    proc_data = ProcData()\n",
    "    \n",
    "    KIO=kineticaIO(gpudb.GPUdb(encoding = 'BINARY', host = headnode, port = 9191))\n",
    "    picklebytes=KIO.SkModel_from_Kinetica(Model_id)\n",
    "    model=pickle.loads(picklebytes)\n",
    "    in_table, out_table = proc_data.input_data[0], proc_data.output_data[0]\n",
    "    out_table.size = in_table.size\n",
    "    for col in cols:\n",
    "        out_table[col][:]=in_table[col][:]\n",
    "    x=np.array(in_table[:][:]).T[:,1:11]\n",
    "    predict=model.predict(x)\n",
    "    out_table[\"predict\"][:]=predict\n",
    "\n",
    "    proc_data.complete()\n",
    "if __name__==\"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register and run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering proc...\n",
      "{'status_info': {u'status': u'OK', u'data_type': u'create_proc_response', u'message': u'', 'response_time': 0.0099}, u'proc_name': u'LR_infer'}\n",
      "Executing proc...\n",
      "Proc was launched successfully with run_id: 14\n",
      "process is running... \n",
      "('total running time is ', datetime.timedelta(0, 3, 782004))\n",
      "Final Proc state: complete\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import time\n",
    "import gpudb\n",
    "from datetime import datetime, timedelta\n",
    "host_ip=\"p4.rewreu.org\" # dev machine\n",
    "PORT = '9191'\n",
    "proc_name = 'LR_infer'\n",
    "filelist=['infer_Reg.py','kineticaIO.py']\n",
    "OUTPUT_TABLE=\"LR_output\"\n",
    "\n",
    "# Register UDF\n",
    "def Register_UDF(h_db,proc_name=proc_name, filelist=filelist):\n",
    "    files = {}\n",
    "    for ifile in filelist:\n",
    "        with open(ifile, 'rb') as f:\n",
    "            files[ifile] = f.read()\n",
    "    if h_db.has_proc(proc_name)['proc_exists']:\n",
    "        h_db.delete_proc(proc_name)\n",
    "    print(\"Registering proc...\")\n",
    "    response = h_db.create_proc(proc_name, 'distributed', files, 'python', [filelist[0]], {})\n",
    "    print(response)\n",
    "\n",
    "# Execute UDF\n",
    "def execute_UDF(h_db,proc_name=proc_name):\n",
    "    print(\"Executing proc...\")\n",
    "    response = h_db.execute_proc(proc_name, {}, {}, [\"X\"], {}, [OUTPUT_TABLE], {})\n",
    "    return response\n",
    "\n",
    "def create_table(h_db):\n",
    "    res=h_db.show_table(\"X\")\n",
    "    type_schema=res[\"type_schemas\"][0]\n",
    "    type_schema=type_schema[:-2]+\"\"\",{\"name\":\"predict\",\"type\":\"float\"}\"\"\"+type_schema[-2:]\n",
    "    properties=res[\"properties\"][0]\n",
    "    \n",
    "    response = h_db.create_type(type_definition = type_schema, label = OUTPUT_TABLE, properties=properties)\n",
    "    if h_db.has_table(table_name = OUTPUT_TABLE)['table_exists']:\n",
    "        h_db.clear_table(table_name = OUTPUT_TABLE)\n",
    "    response=h_db.create_table(table_name = OUTPUT_TABLE, type_id = response['type_id'],\n",
    "                               options={\"collection_name\": \"LinearReg\"})\n",
    "if __name__ == \"__main__\":\n",
    "    h_db = gpudb.GPUdb(encoding='BINARY', host=host_ip,port=PORT)\n",
    "    create_table(h_db)\n",
    "    Register_UDF(h_db)\n",
    "    response=execute_UDF(h_db)\n",
    "    start_time = datetime.now()\n",
    "    if response['status_info']['status'] == 'OK':\n",
    "        run_id = response['run_id']\n",
    "        print('Proc was launched successfully with run_id: ' + run_id)\n",
    "        while h_db.show_proc_status(run_id)['overall_statuses'][run_id] == 'running':\n",
    "            time.sleep(3)\n",
    "            print('process is running... ')\n",
    "        final_proc_state = h_db.show_proc_status(run_id)['overall_statuses'][run_id]\n",
    "        print(\"total running time is \",datetime.now() - start_time)\n",
    "        print('Final Proc state: ' + final_proc_state)\n",
    "        if final_proc_state=='error':\n",
    "            raise RuntimeError('proc error')\n",
    "    else:\n",
    "        print('Error launching proc; response: ')\n",
    "        print(response)\n",
    "        raise RuntimeError('proc error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n",
      "Catalog [KINETICA]\n",
      "Time 0.176\n",
      "+--------------+-------------+--------------+\n",
      "|   real_value |     predict |        error |\n",
      "+--------------+-------------+--------------+\n",
      "|     5.672384 |   6.4574013 |    0.7850175 |\n",
      "|     8.074842 |    7.074363 |    1.0004792 |\n",
      "|    7.9338965 |    8.598011 |    0.6641145 |\n",
      "|     6.284284 |   6.2104464 |   0.07383776 |\n",
      "|     6.058305 |    6.992298 |   0.93399334 |\n",
      "|     7.777841 |    8.113915 |   0.33607435 |\n",
      "|     6.160608 |    6.385312 |   0.22470427 |\n",
      "|      7.22046 |   6.9435635 |   0.27689648 |\n",
      "|    6.3354597 |    6.201312 |   0.13414764 |\n",
      "|      5.33734 |    4.432918 |    0.9044218 |\n",
      "+--------------+-------------+--------------+\n",
      "Rows read = 10\n",
      "Exec time 0.05 Fetch time 0.019\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "./kisql/kisql -h p4.rewreu.org -sql \\\n",
    "\"\"\"\n",
    "SELECT\n",
    "    y as real_value, predict, abs(y-predict) as error\n",
    "FROM LR_output\n",
    "Limit 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
